{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs. Cats Redux\n",
    "- 環境はGoogle Colaboraroryです。\n",
    "- kaggle apiを使用するため、事前にgdriveにkaggle.jsonをアップロードしておく必要があります。\n",
    "- kerasの学習済みモデルを利用し、5foldを行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gdriveへのアクセスとか \n",
    "- 参考:https://qiita.com/yukkyo/items/eb9bae0b82248f9abd28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import io, os\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from google.colab import auth\n",
    "\n",
    "auth.authenticate_user()\n",
    "\n",
    "drive_service = build('drive', 'v3')\n",
    "results = drive_service.files().list(\n",
    "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
    "kaggle_api_key = results.get('files', [])\n",
    "\n",
    "filename = \"/content/.kaggle/kaggle.json\"\n",
    "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "\n",
    "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
    "fh = io.FileIO(filename, 'wb')\n",
    "downloader = MediaIoBaseDownload(fh, request)\n",
    "done = False\n",
    "while done is False:\n",
    "    status, done = downloader.next_chunk()\n",
    "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
    "os.chmod(filename, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a Drive FUSE wrapper.\n",
    "# https://github.com/astrada/google-drive-ocamlfuse\n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "\n",
    "# Generate creds for the Drive FUSE library.\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gdriveマウント用ディレクトリ作成、マウント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2894,
     "status": "ok",
     "timestamp": 1531487605494,
     "user": {
      "displayName": "水谷亮太",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108422504901340273727"
     },
     "user_tz": -540
    },
    "id": "1sUuvG-qF-fJ",
    "outputId": "24e42fad-0212-41a9-cf8d-0022f4009a46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse -o nonempty drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datasetのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle\n",
    "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip /content/.kaggle/competitions/dogs-vs-cats-redux-kernels-edition/train.zip \n",
    "!unzip /content/.kaggle/competitions/dogs-vs-cats-redux-kernels-edition/test.zip "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ディレクトリの作成と学習データの移動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4115,
     "status": "ok",
     "timestamp": 1531487532265,
     "user": {
      "displayName": "水谷亮太",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108422504901340273727"
     },
     "user_tz": -540
    },
    "id": "wW32u2x3tEgU",
    "outputId": "24c8b9c9-d83f-46b2-80fd-d2e8f728ea45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "%mkdir valid\n",
    "%mkdir valid/dogs\n",
    "%mkdir valid/cats\n",
    "\n",
    "%cd /content/train\n",
    "%mkdir cats dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/\n",
    "\n",
    "%cd /content/test\n",
    "%mkdir unknown\n",
    "%mv *.jpg unknown/\n",
    "%cd /content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8257,
     "status": "ok",
     "timestamp": 1531487617489,
     "user": {
      "displayName": "水谷亮太",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108422504901340273727"
     },
     "user_tz": -540
    },
    "id": "WMHpOsR0x_2v",
    "outputId": "69890985-3de5-4303-c147-b7a10264c7c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from keras.applications import inception_resnet_v2,xception,densenet,resnet50,inception_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41105,
     "status": "ok",
     "timestamp": 1531487658628,
     "user": {
      "displayName": "水谷亮太",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108422504901340273727"
     },
     "user_tz": -540
    },
    "id": "rnzq9LfNyDIH",
    "outputId": "14a7a0ad-1e06-4686-8bb9-994af3ad9555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\n",
      "225214464/225209952 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#lay = VGG16(weights='imagenet', include_top=True)\n",
    "lay = inception_resnet_v2.InceptionResNetV2(weights='imagenet', include_top=True)\n",
    "#lay = xception.Xception(include_top=True, weights='imagenet')\n",
    "#lay=densenet.DenseNet201(include_top=True, weights='imagenet')\n",
    "#lay=resnet50.ResNet50(include_top=True, weights='imagenet')\n",
    "#lay=inception_v3.InceptionV3(include_top=True, weights='imagenet')\n",
    "\n",
    "# 全層の重みをフリーズする\n",
    "for layer in lay.layers:\n",
    "    lay.trainable = False\n",
    "    \n",
    "# 2クラス分類する出力層を追加\n",
    "x = lay.layers[-1].output\n",
    "x = Dense(2, activation='softmax', name='predictionsv2')(x)\n",
    "model = Model(inputs=lay.inputs, outputs=x)\n",
    "\n",
    "# コンパイル\n",
    "model.compile(optimizer=SGD(lr=0.01, momentum=0.9, decay=1e-6, nesterov=True),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習の実行\n",
    "- google colaboratoryはバックグラウンド実行は推奨されていない。\n",
    "- いつ切断されてもいいよう1fold毎にモデルと出力をgdriveに保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6601907,
     "status": "ok",
     "timestamp": 1531494494858,
     "user": {
      "displayName": "水谷亮太",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108422504901340273727"
     },
     "user_tz": -540
    },
    "id": "lalq_AA_q2nJ",
    "outputId": "2619f5cd-7cc4-4be7-97df-c58ea6417d32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/5\n",
      "282/313 [==========================>...] - ETA: 1:29 - loss: 0.4665 - acc: 0.8270313/313 [==============================] - 1190s 4s/step - loss: 0.4360 - acc: 0.8405 - val_loss: 0.1579 - val_acc: 0.9605\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 1146s 4s/step - loss: 0.0805 - acc: 0.9824 - val_loss: 0.0532 - val_acc: 0.9871\n",
      "Epoch 3/5\n",
      " 85/313 [=======>......................] - ETA: 10:24 - loss: 0.0448 - acc: 0.9915313/313 [==============================] - 1146s 4s/step - loss: 0.0415 - acc: 0.9912 - val_loss: 0.0403 - val_acc: 0.9909\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 1146s 4s/step - loss: 0.0266 - acc: 0.9951 - val_loss: 0.0351 - val_acc: 0.9916\n",
      "Epoch 5/5\n",
      " 40/313 [==>...........................] - ETA: 12:36 - loss: 0.0203 - acc: 0.9973313/313 [==============================] - 1149s 4s/step - loss: 0.0184 - acc: 0.9965 - val_loss: 0.0291 - val_acc: 0.9934\n",
      "Found 12500 images belonging to 1 classes.\n",
      "/content/valid\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X=[i for i in range(12500)]\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "#cv用リストの作成\n",
    "doglist=np.array(os.listdir(\"/content/train/dogs/\"))\n",
    "catlist=np.array(os.listdir(\"/content/train/cats/\"))\n",
    "\n",
    "fnum=0\n",
    "for train_index, valid_index in kf.split(X):\n",
    "    fnum+=1   \n",
    "    \n",
    "    #fold毎にtrainとvalidのデータを変更\n",
    "    for i in catlist[valid_index]:  \n",
    "        os.rename(\"/content/train/cats/{}\".format(i), \"/content/valid/cats/{}\".format(i))\n",
    "    for i in doglist[valid_index]:  \n",
    "        os.rename(\"/content/train/dogs/{}\".format(i), \"/content/valid/dogs/{}\".format(i))\n",
    "\n",
    "    gen = ImageDataGenerator()\n",
    "\n",
    "    #64枚ずつ学習\n",
    "    batch_size = 64\n",
    "    train_batches = gen.flow_from_directory('/content/train/',\n",
    "                                            target_size=(224, 224),\n",
    "                                            class_mode='categorical',\n",
    "                                            shuffle=True,\n",
    "                                            batch_size=batch_size,\n",
    "                                            )\n",
    "\n",
    "    val_batches = gen.flow_from_directory('/content/valid/',\n",
    "                                        target_size=(224, 224),\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=True,\n",
    "                                        batch_size=batch_size)\n",
    "\n",
    "    #logger作成\n",
    "    logger = CSVLogger('/content/history_k{}.log'.format(fnum))\n",
    "\n",
    "    # monitorしている指標が改善したらモデル（構造・重み含む）をファイルに出力する\n",
    "    #checkpoint = ModelCheckpoint(\n",
    "    #    'dns.{epoch:02d}-{val_loss:.3f}-{val_acc:.3f}.h5',\n",
    "    #    monitor='val_loss',\n",
    "    #    verbose=1,\n",
    "    #    save_best_only=True,\n",
    "    #    mode='auto')\n",
    "\n",
    "    #モデルの実行\n",
    "    model.fit_generator(\n",
    "        train_batches,\n",
    "        steps_per_epoch=int(np.ceil(train_batches.samples / batch_size)),\n",
    "        epochs=5,\n",
    "        validation_data=val_batches,\n",
    "        validation_steps=int(np.ceil(train_batches.samples / batch_size)),\n",
    "        #callbacks=[logger, checkpoint])\n",
    "        callbacks=[logger])\n",
    "\n",
    "    #モデルを毎fold保存、gdriveにアップロード\n",
    "    model.save('k{}_model_dogs_vs_cats.h5'.format(fnum))\n",
    "    shutil.copyfile(\"k{}_model_dogs_vs_cats.h5\".format(fnum), \"/content/drive/k{}_model_dogs_vs_cats.h5\".format(fnum))\n",
    "\n",
    "    #予測\n",
    "    test_batches = gen.flow_from_directory('/content/test/',\n",
    "                                           target_size=(224, 224),\n",
    "                                           class_mode='categorical',\n",
    "                                           shuffle=False,\n",
    "                                           batch_size=batch_size,\n",
    "                                           )\n",
    "    #数分かかる\n",
    "    preds = model.predict_generator(test_batches, int(np.ceil(test_batches.samples / batch_size)))\n",
    "    isdog = preds[:, 1]\n",
    "\n",
    "    # ファイル名からIDを取得\n",
    "    # unknown/8250.jpg => 8250\n",
    "    filenames=np.array(test_batches.filenames)\n",
    "    ids = np.array([int(f[8:f.find('.')]) for f in filenames])\n",
    "\n",
    "    # IDと予測確率を列方向に結合\n",
    "    subm = np.stack([ids, isdog], axis=1)\n",
    "\n",
    "    #submitファイル作成\n",
    "    out=pd.DataFrame(subm)\n",
    "    out.columns=[\"id\",\"label\"]\n",
    "    out.id=out.id.astype(int)\n",
    "    out.to_csv(\"result_k{}.csv\".format(fnum),index=False)\n",
    "\n",
    "    #gdriveにアップロード\n",
    "    shutil.copyfile(\"result_k{}.csv\".format(fnum), \"/content/drive/result_k{}.csv\".format(fnum))\n",
    "    shutil.copyfile(\"/content/history_k{}.log\".format(fnum), \"/content/drive/history_k{}.log\".format(fnum))\n",
    "\n",
    "    #メモリ解法\n",
    "    gc.collect()\n",
    "\n",
    "    #cvするため学習データを戻す\n",
    "    %cd /content/valid\n",
    "    for i in catlist[valid_index]:  \n",
    "        os.rename(\"/content/valid/cats/{}\".format(i), \"/content/train/cats/{}\".format(i))\n",
    "    for i in doglist[valid_index]:  \n",
    "        os.rename(\"/content/valid/dogs/{}\".format(i), \"/content/train/dogs/{}\".format(i))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "cattog_cross_val",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
